{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579a2d10",
   "metadata": {},
   "source": [
    "# Differential Evolution with Newton and custom initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00dd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import isinf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45453bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from math import isinf\n",
    "\n",
    "def fmin_DENewton(\n",
    "    F, dF, ddF,\n",
    "    lower_bounds, upper_bounds,\n",
    "    beta_min, beta_max, pCR,\n",
    "    n_pop, tol_cost, tol_grad, max_it,\n",
    "    newton_LS_size=8,\n",
    "    rng=None,\n",
    "):\n",
    "    rng = rng or np.random.default_rng()\n",
    "    n_var = len(lower_bounds)\n",
    "    lower_bounds = np.asarray(lower_bounds, dtype=float)\n",
    "    upper_bounds = np.asarray(upper_bounds, dtype=float)\n",
    "\n",
    "    # initialise population according to bounds\n",
    "    pop_x = np.empty((n_pop, n_var))\n",
    "    for j in range(n_var):\n",
    "        lo, hi = lower_bounds[j], upper_bounds[j]\n",
    "        if not isinf(lo) and not isinf(hi):\n",
    "            pop_x[:, j] = rng.uniform(lo, hi, size=n_pop)\n",
    "        elif isinf(lo) and isinf(hi):\n",
    "            pop_x[:, j] = rng.normal(size=n_pop)\n",
    "        elif isinf(hi):\n",
    "            pop_x[:, j] = lo + rng.exponential(size=n_pop)\n",
    "        else:  # isinf(lo)\n",
    "            pop_x[:, j] = hi - rng.exponential(size=n_pop)\n",
    "\n",
    "    pop_cost = np.apply_along_axis(F, 1, pop_x)\n",
    "\n",
    "    best_idx = int(np.argmin(pop_cost))\n",
    "    best_x = pop_x[best_idx].copy()\n",
    "    best_cost = pop_cost[best_idx]\n",
    "    best_grad = np.zeros(n_var)\n",
    "    prev_mean = np.inf\n",
    "\n",
    "    for it in range(1, max_it + 1):\n",
    "        mean_cost = pop_cost.mean()\n",
    "        if abs(prev_mean - mean_cost) <= tol_cost and np.linalg.norm(best_grad) <= tol_grad:\n",
    "            break\n",
    "        prev_mean = mean_cost\n",
    "\n",
    "        for i in range(n_pop):\n",
    "            others = [j for j in range(n_pop) if j != i]\n",
    "            a, b, c = rng.choice(others, 3, replace=False)\n",
    "            beta = rng.uniform(beta_min, beta_max, size=n_var)\n",
    "            y = pop_x[a] + beta * (pop_x[b] - pop_x[c])\n",
    "            y = np.minimum(np.maximum(y, lower_bounds), upper_bounds)\n",
    "\n",
    "            j0 = rng.integers(n_var)\n",
    "            mask = rng.random(n_var) < pCR\n",
    "            mask[j0] = True\n",
    "            z = np.where(mask, y, pop_x[i])\n",
    "            z_cost = F(z)\n",
    "\n",
    "            if z_cost < pop_cost[i]:\n",
    "                pop_x[i], pop_cost[i] = z, z_cost\n",
    "                if z_cost < best_cost:\n",
    "                    best_x, best_cost = z.copy(), z_cost\n",
    "\n",
    "            g = dF(pop_x[i])\n",
    "            H = ddF(pop_x[i])\n",
    "            try:\n",
    "                direction = -np.linalg.solve(H, g)\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "\n",
    "            alphas = np.linspace(-1, 1, newton_LS_size)\n",
    "            candidates = pop_x[i] + np.outer(alphas, direction)\n",
    "            candidates = np.clip(candidates, lower_bounds, upper_bounds)\n",
    "            costs_line = np.apply_along_axis(F, 1, candidates)\n",
    "\n",
    "            idx_min = int(np.argmin(costs_line))\n",
    "            z_new = candidates[idx_min]\n",
    "            z_cost = costs_line[idx_min]\n",
    "\n",
    "            if z_cost < pop_cost[i]:\n",
    "                pop_x[i], pop_cost[i] = z_new, z_cost\n",
    "                if z_cost < best_cost:\n",
    "                    best_x, best_cost = z_new.copy(), z_cost\n",
    "                    best_grad = g\n",
    "\n",
    "    return best_x, it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee610ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target parameters\n",
    "a_true = np.array([0.8, 0.4])\n",
    "b_true = np.array([1.0, 3.0])\n",
    "\n",
    "# objective using parametrisation a=exp(a_params), b=exp(cumsum(b_params))\n",
    "def objective(p):\n",
    "    a_params = p[:2]\n",
    "    b_params = p[2:]\n",
    "    a = np.exp(a_params)\n",
    "    b = np.exp(np.cumsum(b_params))\n",
    "    diff = np.concatenate([a - a_true, b - b_true])\n",
    "    return 0.5 * np.sum(diff * diff)\n",
    "\n",
    "def grad(p):\n",
    "    a_params = p[:2]\n",
    "    b_params = p[2:]\n",
    "    a = np.exp(a_params)\n",
    "    b1 = np.exp(b_params[0])\n",
    "    b2 = np.exp(b_params[0] + b_params[1])\n",
    "    g = np.zeros_like(p)\n",
    "    g[0] = (a[0] - a_true[0]) * a[0]\n",
    "    g[1] = (a[1] - a_true[1]) * a[1]\n",
    "    g[2] = (b1 - b_true[0]) * b1 + (b2 - b_true[1]) * b2\n",
    "    g[3] = (b2 - b_true[1]) * b2\n",
    "    return g\n",
    "\n",
    "def hess(p):\n",
    "    a_params = p[:2]\n",
    "    b_params = p[2:]\n",
    "    a = np.exp(a_params)\n",
    "    b1 = np.exp(b_params[0])\n",
    "    b2 = np.exp(b_params[0] + b_params[1])\n",
    "    H = np.zeros((4,4))\n",
    "    H[0,0] = (2*a[0] - a_true[0]) * a[0]\n",
    "    H[1,1] = (2*a[1] - a_true[1]) * a[1]\n",
    "    H_bb1 = (2*b1 - b_true[0]) * b1\n",
    "    H_bb2 = (2*b2 - b_true[1]) * b2\n",
    "    H[2,2] = H_bb1 + H_bb2\n",
    "    H[2,3] = H_bb2\n",
    "    H[3,2] = H_bb2\n",
    "    H[3,3] = H_bb2\n",
    "    return H\n",
    "\n",
    "lower = np.array([-np.inf, -np.inf, -np.inf, 0.0])\n",
    "upper = np.array([np.inf, np.inf, np.inf, np.inf])\n",
    "\n",
    "best, it = fmin_DENewton(\n",
    "    objective, grad, hess,\n",
    "    lower, upper,\n",
    "    beta_min=0.5, beta_max=1.0, pCR=0.9,\n",
    "    n_pop=20, tol_cost=1e-8, tol_grad=1e-8, max_it=100,\n",
    ")\n",
    "print('best params:', best)\n",
    "print('iterations:', it)\n",
    "print('recovered a:', np.exp(best[:2]))\n",
    "print('recovered b:', np.exp(np.cumsum(best[2:])))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
